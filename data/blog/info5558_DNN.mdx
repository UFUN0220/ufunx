---
title: 'INFO5558 Deep Neural Networks Sol.'
date: '2026-01-13'
lastmod: '2026-01-13'
tags: ['']
summary: ''
images: []
authors: ['default']
---

会持续更新完本课程所有作业解析。

# dnn_assgn_3

Assgn3要求：

https://github.com/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_t81_558_class3.ipynb

使用 `crx` 数据集（信用卡审批数据）构建一个**二分类神经网络**。对数据进行预处理（填补缺失值、编码分类变量），然后使用 **Early Stopping**（早停法）训练模型。最终，预测整个数据集（包括训练集和验证集）中每个样本属于 "+" 或 "-" 的概率。

```Python
import os
import pandas as pd
from scipy.stats import zscore
import numpy as np
import torch
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from torch import nn
from torch.autograd import Variable
from torch.utils.data import DataLoader, TensorDataset
from sklearn.impute import SimpleImputer

file = ".../assignment_FangYou_t81_558_class3.ipynb"
df = pd.read_csv(".../crx.csv", na_values=['?'])

key = ""

X = df.drop('a16', axis=1)
y = df['a16']

categorical_cols = X.select_dtypes(include=['object']).columns.tolist()
numerical_cols = X.select_dtypes(include=['number']).columns.tolist()

imputer = SimpleImputer(strategy='median')
X_numerical_imputed = imputer.fit_transform(X[numerical_cols])
X[numerical_cols] = X_numerical_imputed

for col in categorical_cols:
    if X[col].isnull().any():
        mode_val = X[col].mode()[0]
        X.loc[X[col].isnull(), col] = mode_val

X_encoded = pd.get_dummies(X, columns=categorical_cols, drop_first=True)

le = LabelEncoder()
y_encoded = le.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(
    X_encoded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_tensor = torch.FloatTensor(X_train_scaled)
y_train_tensor = torch.LongTensor(y_train)
X_test_tensor = torch.FloatTensor(X_test_scaled)
y_test_tensor = torch.LongTensor(y_test)

train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)

class CreditNet(nn.Module):
    def __init__(self, input_size):
        super(CreditNet, self).__init__()
        self.fc1 = nn.Linear(input_size, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 2)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.3)

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.dropout(x)
        x = self.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x

input_size = X_train_scaled.shape[1]
model = CreditNet(input_size)
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

patience = 10
best_loss = float('inf')
counter = 0
epochs = 100
best_model_state = None

for epoch in range(epochs):
    model.train()
    train_loss = 0
    for batch_X, batch_y in train_loader:
        optimizer.zero_grad()
        outputs = model(batch_X)
        loss = criterion(outputs, batch_y)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()

    model.eval()
    with torch.no_grad():
        val_outputs = model(X_test_tensor)
        val_loss = criterion(val_outputs, y_test_tensor).item()

    if val_loss < best_loss:
        best_loss = val_loss
        counter = 0
        best_model_state = model.state_dict().copy()
    else:
        counter += 1
        if counter >= patience:
            print(f"Early stopping at epoch {epoch+1}")
            break

    if (epoch + 1) % 10 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}')

if best_model_state is not None:
    model.load_state_dict(best_model_state)

X_full = X_encoded.copy()
X_full_scaled = scaler.transform(X_full)
X_full_tensor = torch.FloatTensor(X_full_scaled)

model.eval()
with torch.no_grad():
    outputs = model(X_full_tensor)
    probabilities = torch.softmax(outputs, dim=1).numpy()

df_submit = pd.DataFrame({
    '+': probabilities[:, 1],
    '-': probabilities[:, 0]
})

print("Submission data shape:", df_submit.shape)
print("First few predictions:")
print(df_submit.head())

submit(source_file=file, data=[df_submit], key=key, course="t81-558", no=3)
```

# dnn_assgn_2

Assgn2要求：https://github.com/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_t81_558_class2.ipynb

加载指定的 CSV 文件并进行数据清洗或转换。

```Python
import os
import pandas as pd
from scipy.stats import zscore

key = ""
file='./assignment_FangYou_t81_558_class2.ipynb'

df = pd.read_csv(".../reg-36-data.csv")
print(len(df))

# 1.
df['ratio'] = df['max'] / df['number']

# 2.
cat2_dummies = pd.get_dummies(df['cat2'], prefix='cat2')
df = pd.concat([df, cat2_dummies], axis=1)
df.drop('cat2', axis=1, inplace=True)

# 3.
item_dummies = pd.get_dummies(df['item'], prefix='item')
df = pd.concat([df, item_dummies], axis=1)
df.drop('item', axis=1, inplace=True)

# 4.
length_median = df['length'].median()
df = df.assign(length=df['length'].fillna(length_median))

# 5.
height_median = df['height'].median()
df = df.assign(height=df['height'].fillna(height_median))
df['height'] = zscore(df['height'])

# 6.
columns_to_keep = ['height', 'max', 'number', 'length', 'ratio']
cat2_columns = [col for col in df.columns if col.startswith('cat2_')]
item_columns = [col for col in df.columns if col.startswith('item_')]

all_columns_to_keep = columns_to_keep + cat2_columns + item_columns
df = df[all_columns_to_keep]

required_cat2_columns = ['cat2_CA-0', 'cat2_CA-1', 'cat2_CA-10', 'cat2_CA-11', 'cat2_CA-12',
                         'cat2_CA-13', 'cat2_CA-14', 'cat2_CA-15', 'cat2_CA-16', 'cat2_CA-17',
                         'cat2_CA-18', 'cat2_CA-19', 'cat2_CA-1A', 'cat2_CA-1B', 'cat2_CA-1C',
                         'cat2_CA-1D', 'cat2_CA-1E', 'cat2_CA-1F', 'cat2_CA-2', 'cat2_CA-20',
                         'cat2_CA-21', 'cat2_CA-22', 'cat2_CA-23', 'cat2_CA-24', 'cat2_CA-25',
                         'cat2_CA-26', 'cat2_CA-27', 'cat2_CA-3', 'cat2_CA-4', 'cat2_CA-5',
                         'cat2_CA-6', 'cat2_CA-7', 'cat2_CA-8', 'cat2_CA-9', 'cat2_CA-A',
                         'cat2_CA-B', 'cat2_CA-C', 'cat2_CA-D', 'cat2_CA-E', 'cat2_CA-F']

required_item_columns = ['item_IT-0', 'item_IT-1', 'item_IT-10', 'item_IT-11', 'item_IT-12',
                         'item_IT-13', 'item_IT-14', 'item_IT-15', 'item_IT-16', 'item_IT-17',
                         'item_IT-18', 'item_IT-19', 'item_IT-1A', 'item_IT-1B', 'item_IT-1C',
                         'item_IT-1D', 'item_IT-1E', 'item_IT-2', 'item_IT-3', 'item_IT-4',
                         'item_IT-5', 'item_IT-6', 'item_IT-7', 'item_IT-8', 'item_IT-9',
                         'item_IT-A', 'item_IT-B', 'item_IT-C', 'item_IT-D', 'item_IT-E',
                         'item_IT-F']

for col in required_cat2_columns:
    if col not in df.columns:
        df[col] = 0

for col in required_item_columns:
    if col not in df.columns:
        df[col] = 0

final_columns = ['height', 'max', 'number', 'length', 'ratio'] + required_cat2_columns + required_item_columns
df = df[final_columns]

df.to_csv('2.csv',index=False)
submit(source_file=file,data=[df],key=key,course='t81-558',no=2)
```

# dnn_assgn_1

Assgn1要求：https://github.com/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_t81_558_class1.ipynb

熟悉提交函数与提交作业模式。

我不习惯用colab，基本都用jupyter notebook完成。

所有作业先运行Assignment Submit Function，随后运行如下代码。

```Bash
key = "..." //替换成自己的，密钥有问题给Jeff发邮件

file = '.../assignment_FangYou_t81_558_class1.ipynb' //替换成自己的文件路径

//主函数
df = pd.DataFrame({'a' : [0, 0, 1, 1], 'b' : [0, 1, 0, 1], 'c' : [0, 1, 1, 0]})

//调用提交函数
submit(source_file=file, data=[df], key=key, course='t81-558', no=1)

//每次提交作业时，建议先注释掉submit函数，本地测试结果符合预期后再提交。
```
